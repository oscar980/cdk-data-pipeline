# CDK Data Pipeline

Pipeline de datos completo usando AWS CDK con Lambda, Glue, Athena y Lake Formation.

## ğŸ—ï¸ Arquitectura

```
Lambda (Ingesta) â†’ S3 â†’ Glue Crawler â†’ Glue Database â†’ Athena
```

### Componentes:
- **StorageStack**: Buckets S3 para datos y resultados
- **IngestionStack**: Lambda para ingesta de datos desde APIs
- **GlueStack**: Base de datos y crawler para detecciÃ³n de esquemas
- **AthenaStack**: WorkGroup para consultas SQL

## ğŸš€ Despliegue

### Prerequisitos:
- AWS CLI configurado
- CDK instalado (`npm install -g aws-cdk`)
- Python 3.9+
- Credenciales AWS vÃ¡lidas

### Pasos:

1. **Clonar el repositorio:**
   ```bash
   git clone https://github.com/oscar980/cdk-data-pipeline.git
   cd cdk-data-pipeline
   ```

2. **Instalar dependencias:**
   ```bash
   python -m venv .venv
   source .venv/bin/activate  # Linux/Mac
   # .venv\Scripts\activate  # Windows
   pip install -r requirements.txt
   ```

3. **Configurar variables de entorno:**
   ```bash
   cp .aws.example .aws
   # Editar .aws con tus credenciales
   ```

4. **Desplegar:**
   ```bash
   ./deploy.sh
   ```

## ğŸ”§ ConfiguraciÃ³n de Lake Formation

**IMPORTANTE**: DespuÃ©s del despliegue, necesitas otorgar permisos de Lake Formation:

```bash
# 1. Permisos al rol de Glue para la base de datos
aws lakeformation grant-permissions --cli-input-json file://grant_permissions.json --region us-east-1

# 2. Permisos al rol de Glue para S3
aws lakeformation grant-permissions --cli-input-json file://grant_s3_permissions.json --region us-east-1

# 3. Permisos al root para la base de datos
aws lakeformation grant-permissions --cli-input-json file://grant_root_permissions.json --region us-east-1

# 4. Permisos al root para S3
aws lakeformation grant-permissions --cli-input-json file://grant_root_s3_permissions.json --region us-east-1

# 5. Permisos al root para la tabla
aws lakeformation grant-permissions --cli-input-json file://grant_root_table_permissions.json --region us-east-1
```

## ğŸ“Š Uso

### 1. Ejecutar Lambda de ingesta:
```bash
aws lambda invoke \
  --function-name IngestionStack-IngestionLambdaEF25F265 \
  --payload '{"api_url": "https://jsonplaceholder.typicode.com/users"}' \
  response.json \
  --region us-east-1
```

### 2. Ejecutar Glue Crawler:
```bash
aws glue start-crawler --name cdk_data_pipeline_crawler --region us-east-1
```

### 3. Consultar en Athena:
```sql
SELECT * FROM cdk_data_pipeline_db_users.users LIMIT 5;
```

## ğŸ§ª Testing

```bash
python -m pytest tests/unit/ -v
```

## ğŸ“ Estructura del Proyecto

```
cdk-data-pipeline/
â”œâ”€â”€ cdk_data_pipeline/
â”‚   â”œâ”€â”€ storage_stack.py      # Buckets S3
â”‚   â”œâ”€â”€ ingestion_stack.py    # Lambda de ingesta
â”‚   â”œâ”€â”€ glue_stack.py         # Glue Database y Crawler
â”‚   â”œâ”€â”€ athena_stack.py       # Athena WorkGroup
â”‚   â””â”€â”€ lambda_src/
â”‚       â””â”€â”€ data_ingestion.py  # CÃ³digo Lambda
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ unit/
â”‚       â””â”€â”€ test_cdk_data_pipeline_stack.py
â”œâ”€â”€ app.py                    # AplicaciÃ³n principal CDK
â”œâ”€â”€ deploy.sh                 # Script de despliegue
â”œâ”€â”€ grant_*.json              # Archivos de permisos Lake Formation
â””â”€â”€ requirements.txt          # Dependencias Python
```

## ğŸ”§ ConfiguraciÃ³n

### Variables de entorno (.aws):
```bash
export CDK_DEFAULT_ACCOUNT="your-account-id"
export CDK_DEFAULT_REGION="us-east-1"
export AWS_ACCESS_KEY_ID="your-access-key"
export AWS_SECRET_ACCESS_KEY="your-secret-key"
```

## ğŸ·ï¸ Recursos Creados

- **S3 Buckets**: 
  - `cdk-data-bucket-oscar` (datos)
  - `cdk-athena-results-oscar` (resultados)
- **Lambda**: `IngestionStack-IngestionLambdaEF25F265`
- **Glue Database**: `cdk_data_pipeline_db_users`
- **Glue Crawler**: `cdk_data_pipeline_crawler`
- **Athena WorkGroup**: `cdk_data_pipeline_wg_users`

## ğŸ§¹ Limpieza

```bash
cdk destroy --all
```

## ğŸ“ Notas

- **Lake Formation**: Se activa automÃ¡ticamente con Glue
- **Permisos**: Requieren configuraciÃ³n manual inicial usando los archivos `grant_*.json`
- **Formato de datos**: JSONL (JSON Lines) para mejor compatibilidad
- **Esquema**: Detectado automÃ¡ticamente por el crawler

## ğŸ¤ Contribuir

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request